ChatAPI = "http://localhost:8080/v1/chat/completions"
CompletionAPI = "http://localhost:8080/completion"
FetchModelNameAPI = "http://localhost:8080/v1/models"
# in case you have deepseek token
DeepSeekCompletionAPI = "https://api.deepseek.com/beta/completions"
DeepSeekChatAPI = "https://api.deepseek.com/chat/completions"
DeepSeekModel = "deepseek-reasoner"
# DeepSeekToken = ""
# in case you have opentouter token
OpenRouterCompletionAPI = "https://openrouter.ai/api/v1/completions"
OpenRouterChatAPI = "https://openrouter.ai/api/v1/chat/completions"
# OpenRouterToken = ""
EmbedURL = "http://localhost:8082/v1/embeddings"
ShowSys = true
LogFile = "log.txt"
UserRole = "user"
ToolRole = "tool"
AssistantRole = "assistant"
SysDir = "sysprompts"
ChunkLimit = 100000
AutoScrollEnabled = true
AutoCleanToolCallsFromCtx = false
# rag settings
RAGBatchSize = 1
RAGWordLimit = 80
RAGWorkers = 2
RAGDir = "ragimport"
# extra tts
TTS_ENABLED = false
TTS_URL = "http://localhost:8880/v1/audio/speech"
TTS_SPEED = 1.2
TTS_PROVIDER = "kokoro"
TTS_LANGUAGE = "en"
# extra stt
STT_ENABLED = false
STT_TYPE = "WHISPER_SERVER" # WHISPER_SERVER or WHISPER_BINARY
STT_URL = "http://localhost:8081/inference"
WhisperBinaryPath = "./batteries/whisper.cpp/build/bin/whisper-cli" # Path to whisper binary (for WHISPER_BINARY mode)
WhisperModelPath = "./batteries/whisper.cpp/ggml-large-v3-turbo-q5_0.bin"  # Path to whisper model file (for WHISPER_BINARY mode)
STT_LANG = "en"  # Language for speech recognition (for WHISPER_BINARY mode)
STT_SR = 16000  # Sample rate for audio recording
#
DBPATH = "gflt.db"
FilePickerDir = "." # Directory where file picker should start
FilePickerExts = "png,jpg,jpeg,gif,webp" # Comma-separated list of allowed file extensions for file picker
CodingDir = "." # Default directory for coding assistant file operations (relative paths resolved against this)
EnableMouse = false # Enable mouse support in the UI
# character specific context
CharSpecificContextEnabled = true
CharSpecificContextTag = "@"
AutoTurn = true
StripThinkingFromAPI = true  # Strip <think> blocks from messages before sending to LLM (keeps them in chat history)
# OpenRouter reasoning configuration (only applies to OpenRouter chat API)
# Valid values: xhigh, high, medium, low, minimal, none (empty or none = disabled)
# Models that support reasoning will include thinking content wrapped in <think> tags
ReasoningEffort = "medium"
